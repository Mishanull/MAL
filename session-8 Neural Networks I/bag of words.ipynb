{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words example\n",
    "\n",
    "This notebook is a brief introduction to using bag of words. It is not meant as a guide to building a good Natural Language Processing network (it doesn't).\n",
    "\n",
    "The data used in this example is from Kaggle's Disaster Tweets: https://www.kaggle.com/competitions/nlp-getting-started/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tweets = pd.read_csv('train.csv')\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is 1, if the tweet is about a disaster, and 0 otherwise. We'll try to \n",
    "\n",
    "Since this is about NLP, I'll just use the text even though the keyword looks useful.\n",
    "\n",
    "The CountVectorizer finds all distinct words in the body of text (that is, all the rows). It returns a vector for each input text. The vector has a word count for how many times the word occured in the input text.\n",
    "\n",
    "Note the conversions to numpy arrays. Keras is none to happy with Pandas Dataframes.\n",
    "\n",
    "The shape of _X_ reveals that we have 7613 vectors (texts) and 21637 distinct words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "y = np.array(tweets['target'])\n",
    "X = vectorizer.fit_transform(tweets['text']).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_, X_test, y_, y_test = train_test_split(X, y, train_size=.8, random_state=504)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_, y_, train_size=.75, random_state=504)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANN below is horribly overfitting (never a good sign when validation loss is increasing), but I'll leave it here. \n",
    "\n",
    "Note how the input dimension is related to the shape of the input.\n",
    "\n",
    "Also note that this had two hidden layers, where the portfolio exercise requires one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "ann = tf.keras.Sequential([\n",
    "    layers.Dense(units=100, input_dim=X.shape[1], activation='relu'),\n",
    "    layers.Dense(units=100, activation='relu'),\n",
    "    layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "ann.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "history = ann.fit(X_train, y_train, epochs = 100, validation_data=(X_validate, y_validate), callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Learning curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross entropy loss\")\n",
    "plt.plot(history.history['loss'], label = 'train')\n",
    "plt.plot(history.history['val_loss'], label = 'valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
